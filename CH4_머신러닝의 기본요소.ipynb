{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "케라스_창시자에게_배우는_딥러닝.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOArb22/7wwNRRuiw6EPK2k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkmina365/deep_learning_with_python/blob/main/CH4_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%98%20%EA%B8%B0%EB%B3%B8%EC%9A%94%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Y5EGlAVlGu"
      },
      "source": [
        "# 4장. 머신러닝의 기본 요소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXXh3mTAVqPT"
      },
      "source": [
        "## 4.1 머신러닝의 네 가지 분류\n",
        "4.1.1 지도학습\n",
        "4.1.2 비지도학습\n",
        "4.1.3 자기 지도 학습\n",
        "- Autoencoder\n",
        "4.1.4 강화 학습\n",
        "- 알파고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6L43WxZWt4z"
      },
      "source": [
        "## 4.2 머신 러닝 모델 평가\n",
        "4.2.1 훈련, 검증, 테스트 세트\\\n",
        "4.2.2 기억해야 할 것\n",
        "- 대표성 있는 데이터\n",
        "- 시간의 방향\n",
        "- 데이터 중복 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGL5-Ze-XfZT"
      },
      "source": [
        "## 4.3 데이터 전처리, 특성 공학, 특성 학습\n",
        "4.3.1 신경망을 위한 데이터 전처리\n",
        "- 벡터화\n",
        "- 값 정규화\n",
        "- 누락된 값 다루기\n",
        "- 특성 추출\n",
        "\n",
        "4.3.2 특성 공학(Feature Engineering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpAzZFFQY8N_"
      },
      "source": [
        "## 4.4 과대적합과 과소적합\n",
        "- 과대적합 방지 방법\n",
        "  - 훈련 데이터를 더 모음\n",
        "  - 네트워크의 용량을 감소시킴\n",
        "  - 가중치 규제를 추가\n",
        "  - 드롭아웃 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD3FwF37YulF"
      },
      "source": [
        "4.4.1 네트워크 크기 축소"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ5G-QJnPhff"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)\n",
        "# 레이블을 벡터로 변환합니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46tPTqO7Qhye"
      },
      "source": [
        "# 원본 모델\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "original_model = models.Sequential()\n",
        "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "original_model.add(layers.Dense(16, activation='relu'))\n",
        "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "original_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_3XyL4QonH"
      },
      "source": [
        "# 작은 용량의 모델\n",
        "smaller_model = models.Sequential()\n",
        "smaller_model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
        "smaller_model.add(layers.Dense(6, activation='relu'))\n",
        "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "smaller_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNeCg2hlRn3d"
      },
      "source": [
        "original_hist = original_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrCvubx5SyRR"
      },
      "source": [
        "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abecKWOySbky"
      },
      "source": [
        "epochs=range(1,21)\n",
        "original_val_loss = original_hist.history['val_loss']\n",
        "smaller_val_loss = smaller_model_hist.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSF3ErYS95G"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, smaller_val_loss, 'bo', label='Small model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylAZxrU4UWd5"
      },
      "source": [
        "# 큰 용량의 모델\n",
        "bigger_model = models.Sequential()\n",
        "bigger_model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
        "bigger_model.add(layers.Dense(1024, activation='relu'))\n",
        "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "bigger_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AET282tKUoIX"
      },
      "source": [
        "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))\n",
        "epochs=range(1,21)\n",
        "original_val_loss = original_hist.history['val_loss']\n",
        "bigger_val_loss = bigger_model_hist.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG4Hwr5QUhfL"
      },
      "source": [
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_val_loss, 'bo', label='Big model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 용량이 큰 네트워크는 첫번째 에포크 이후 바로 과대적합 시작. 검증손실도 불안정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdFfBhgTXHIO"
      },
      "source": [
        "original_train_loss = original_hist.history['loss']\n",
        "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
        "\n",
        "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Traning loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 용량이 큰 네트워크는 훈련 손실이 매우 빠르게 0에 가까워짐\n",
        "### 용량이 많은 네트워크일수록 더 빠르게 훈련 데이터를 모델링 할 수 있음(훈련 손실이 낮아짐)\n",
        "### 그러나 과대 적합에 민감해짐(훈련과 검증 손실 사이에 큰 차이가 발생함)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niN4jj_7Y39a"
      },
      "source": [
        "4.4.2 가중치 규제 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z2CnpJpY6zB"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "l2_model = models.Sequential()\n",
        "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu', input_shape=(10000,)))\n",
        "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu'))\n",
        "l2_model.add(layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0sSZvLzd2lz"
      },
      "source": [
        "l2_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgHQE26wd7Uc"
      },
      "source": [
        "l2_model_hist = l2_model.fit(x_train, y_train,\n",
        "                             epochs=20, batch_size=512,\n",
        "                             validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efu_70faec4v"
      },
      "source": [
        "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 두 모델이 동일한 파라미터수를 가지고 있더라도 L2규제를 사용한 모델이 기본 모델보다 과대적합에 잘 견디고 있음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBs93ADfu3T"
      },
      "source": [
        "### l1(0.001) 모델과 비교해보기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BefQN-Txf4qH"
      },
      "source": [
        "4.4.3 드롭아웃 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNcG0Saf70S"
      },
      "source": [
        "dpt_model = models.Sequential()\n",
        "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(16, activation='relu'))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "dpt_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ItoG-viSXQ"
      },
      "source": [
        "dpt_model_hist = dpt_model.fit(x_train, y_train, epochs=20,\n",
        "                               batch_size=512,\n",
        "                               validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnuGrhl1iokQ"
      },
      "source": [
        "dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-137JwEjrnw"
      },
      "source": [
        "## 4.5 보편적인 머신 러닝 작업 흐름"
      ]
    }
  ]
}