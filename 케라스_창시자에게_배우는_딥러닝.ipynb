{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "케라스_창시자에게_배우는_딥러닝.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNNgeLN0phG7GZev9RngID",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkmina365/deep_learning_with_python/blob/main/%EC%BC%80%EB%9D%BC%EC%8A%A4_%EC%B0%BD%EC%8B%9C%EC%9E%90%EC%97%90%EA%B2%8C_%EB%B0%B0%EC%9A%B0%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wriB0KIYAxj7"
      },
      "source": [
        "# 1장. 딥러닝이란 무엇인가?\n",
        "\n",
        "## 1.1 인공 지능과 머신 러닝, 딥러닝\n",
        "1.1.1 인공 지능\n",
        "- Artificial Intelligence. 보통의 사람이 수행하는 지능적인 작업을 자동화 하기 위한 연구 활동(Ruled-based Programming) 심볼릭 AI는 체스 게임 등 논리적인 문제를 푸는데 적합하나 이미지 분류, 음성인식, 언어번역 등의 복잡한 문제를 해결하기는 부적합. 이를 해결하기 위해 머신 러닝의 개념이 등장\n",
        "\n",
        "1.1.2 머신 러닝\n",
        "- 규칙과 규칙에 따라 처리될데이터를 입력하면 해답이 출력되는 전통적 프로그래밍인 심볼릭 AI와는 달리, 머신러닝은 데이터와 데이터로부터 기대되는 해답을 입력하면 규칙이 출력됨. 이 규칙을 새로운 데이터에 적용하면 창의적인 답을 만들 수 있음. 머신러닝 시스템은 명시적으로 프로그램 되는것이 아니라 훈련(Training)됨. 작업과 관련있는 많은 샘픔을 제공하면 데이터에서 통계적 구조를 찾아 그 작업을 자동화하기 위한 규칙을 만들어냄. 정통적 통계와 머신러닝이 다른점은 대량의 복잡한 데이터셋을 다루기에 전통적인 통꼐분석 방법은 현실적으로 적용하기가 힘듦. 머신러닝, 딥러닝은 수학적 이론이 부족하며 엔지니어링 지향임. 이론보다는 경험을 바탕으로 아이디어가 증명되는 경향\n",
        "\n",
        "1.1.3 데이터에서 표현을 학습하기\\\n",
        "머신러닝은 샘플과 기댓값이 주어졌을때 데이터 처리 작업을 위한 실행규칙을 찾아내는 것. 머신러닝을 위해 필요한 세가지는 다음과 같음\n",
        "- 1.입력 데이터 포인트\n",
        "- 2.기대출력\n",
        "- 3.알고리즘의 성능을 측정하는 방법: 알고리즘의 현재 출력과 기대 출력간의 차이를 결정하기 위해 필요. 측정값은 알고리즘의 작동 방식을 교정하기 위한 신호로 다시 피드백 됨. 이런 수정단계를 학습(learning)이라고 함\n",
        "- 머신러닝은 가능성있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것. 공간의 변환을 찾기 위한 창의력은 없음. 가설 공간이라 불리는 미리 정의된 연산의 모음들을 자세히 조사하는 것 뿐\n",
        "\n",
        "1.1.4 딥러닝에서 ‘딥’이란 무엇일까?\n",
        "- 머신 러닝의 한 분야. 연속된 층에서 점진적으로 의미 있는 표현을 배우는 데 강점이 있으며 데이터로부터 표현을 학습하는 새로운 방식.\n",
        "- deep이란 깊다는 의미는 아니며 연속된 층으로 표현을 학습한다는 개념임. 데이터로부터 얼마나 많은 층을 사용했는지가 그 모델의 깊이가 됨. 층 기반 표현 학습, 계층적 표현 학습. 머신러닝은 1~2개 데이터 표현층을 학습하는 경향이 있음\n",
        "\n",
        "1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기\n",
        "- 학습은 주어진 입력을 정확한 타겟에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미함(신경망은 가중치를 파라미터로 가짐)\n",
        "- 손실함수(= 목적함수, 비용함수): 신경망의 출력을 제어하기 위해 출력이 기대하는 것보다 얼마나 벗어났는지를 측정. 신경망이 한 샘플에 대해 얼마나 잘 예측했는지 측정하기 위해 손실 함수가 신경망의 예측과 진짜 타깃(신경망의 출력으로 기대하는 값)의 차이를 점수로 계산\n",
        "- 손실함수로 계산한 손실점수를 피드백 신호로 사용하여 현재 샘플의 손실 점수가 감소되는 방향으로 가중치 값을 조금씩 수정하는 것. 딥러닝의 핵심 알고리즘인 역전파(Backpropagation) 알고리즘을 구현한 옵티마이저가 이를 담당함\n",
        "- 훈련 반복(Training loop): 네트워크가 모든 샘플을 처리하면서 가중치가 역전파 알고리즘에 의해 올바른 방향으로 조정되며 손실 점수가 감소되는 것. 충분한 횟수만큼 만복하면 손실 함수를 최소화 하는 가중치 값이 산출 됨\n",
        "\n",
        "1.1.6 지금까지 딥러닝의 성과\n",
        "- 기계에서 해결이 어려웠던 시청각 지각에서의 성과를 보이고 있음\n",
        "\n",
        "1.1.7 단기간의 과대 선전을 믿지 말자\\\n",
        "1.1.8 AI에 대한 전망\n",
        "\n",
        "##1.2 딥러닝 이전: 머신 러닝의 간략한 역사\n",
        "1.2.1 확률적 모델링\\\n",
        "1.2.2 초창기 신경망\\\n",
        "1.2.3 커널 방법\\\n",
        "1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신\\\n",
        "1.2.5 다시 신경망으로\n",
        "- 심층 합성공 신경망(Deep Convolutional neural network, ConvNet)의 등장\n",
        "1.2.6 딥러닝의 특징\n",
        "- 딥러닝은 머신러닝의 특성공학을 완전 자동화 함\n",
        "1.2.7 머신 러닝의 최근 동향\n",
        "\n",
        "## 1.3 왜 딥러닝일까? 왜 지금일까?\n",
        "1.3.1 하드웨어\\\n",
        "1.3.2 데이터\\\n",
        "1.3.3 알고리즘\\\n",
        "1.3.4 새로운 투자의 바람\\\n",
        "1.3.5 딥러닝의 대중화\\\n",
        "1.3.6 지속될까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIsc89PEBSjv"
      },
      "source": [
        "# 2장. 시작하기 전에: 신경망의 수학적 구성 요소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NbADtaCSMrF"
      },
      "source": [
        "## 2.1 신경망과의 첫 만남"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XLauwJGNp3m",
        "outputId": "1f3873b6-d977-477a-e587-24a4baed1940"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "# os.symlink('/content/drive/My Drive/Colab Notebooks', my_path)\n",
        "# sys.path.insert(0,my_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gCiokfGN8EO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc0qJ8YeEfOI"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) =  mnist.load_data()\n",
        "print(train_images.shape, len(train_labels))\n",
        "print(test_images.shape, len(test_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi1uA-EbPXpU"
      },
      "source": [
        "# 이미지 예시 확인\n",
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSEZRgdyGA5_"
      },
      "source": [
        "# 신경망 구조\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "# 10개의 확률점수가 들어있는 배열. 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o3JyaMpIMOg"
      },
      "source": [
        "# 컴파일 단계\n",
        "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# 손실함수(loss fuction): 훈련 데이터에서 신경망의 성능을 측정하는 방법. 네트워크가 옳은 방향으로 학습하게 도와줌\n",
        "# optimizer: 입력된 데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘\n",
        "# metrics: acuuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqyCOV_SPHbQ"
      },
      "source": [
        "print(train_images[0].dtype)\n",
        "### float로 변경해야"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aWoL5bAJG7g"
      },
      "source": [
        "# 이미지 데이터 준비하기\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32')/255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-FyJsgKP_xz"
      },
      "source": [
        "test_images[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jukywjLpJoJF"
      },
      "source": [
        "# 레이블 준비하기\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3rx__sHQeBX",
        "outputId": "f3762b6c-44db-4efe-cec7-bf8c478b50d4"
      },
      "source": [
        "# 신경망 훈련\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "# 네트워크의 손실, 정확도 출력"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2559 - accuracy: 0.9268\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1043 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0685 - accuracy: 0.9795\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0498 - accuracy: 0.9847\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0370 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf95a7b690>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBF2yk5YQ7Ot",
        "outputId": "2d187394-3c30-4991-83d5-ebee4ead7297"
      },
      "source": [
        "# 신경망 테스트\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "### train의 accuracy보다는 낮은 결과(0.9788 < 0.9886). 과대적합 가능성!"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mUiVElrEbER"
      },
      "source": [
        "\n",
        "## 2.2 신경망을 위한 데이터 표현\n",
        "\n",
        "- tensor: 데이터를 담는 컨테이너. 2D텐서의 예시는 행렬. 텐서는 임의의 차원 개수를 가지는 행렬의 일반화된 모습. 텐서에서는 차원(dimension)을 축(axis)이라고 부름\n",
        "\n",
        "2.2.1 스칼라(0D 텐서)\\\n",
        "스칼라 텐서의 축 개수는 0(ndim==0). 텐서의 축 갯수를 랭크(rank)라고도 부름\n",
        "\n",
        "\n",
        "2.2.2 벡터(1D 텐서)\\\n",
        "벡터의 원소가 5개인 경우 5차원 벡터라고도 부름. 5D벡터(=1D텐서) != 5D텐서\n",
        "\n",
        "2.2.3 행렬(2D 텐서)\\\n",
        "2.2.4 3D 텐서와 고차원 텐서\\\n",
        "2.2.5 핵심 속성\n",
        "- 축의 개수(rank): numpy의 ndim으로 확인 가능\n",
        "- 크기(shape): 텐서의 각 축을 따라 얼마나 많은 차원이 있는지 나타낸 파이썬의 튜플임\n",
        "- 데이터 타입: numpy의 dtype으로 확인가능. float32, unit8 등. 텐서는 사전에 할당되어 연속된 메모리에 저장되어야 하므로 넘파이 배열은 가변 길이의 문자열을 지원하지 않음\n",
        "\n",
        "2.2.6 넘파이로 텐서 조작하기\\\n",
        "2.2.7 배치 데이터\\\n",
        "딥러닝에서 사용하는 모든 데이터 텐서의 첫번째 축은 샘플축(sample axis, sample dimension)임. 딥러닝 모델은 한번에 전체 데이터셋을 처리하지 않으며 데이터 샘플들로 분할하여 작은 배치(batch)로 나눔. 이런 배치 데이터를 다룰때 첫번째 축을 배치축(batch axis, batch dimension)이라고 부름\\\n",
        "2.2.8 텐서의 실제 사례\n",
        "- 2D 텐서: 벡터 데이터. (samples, features) 형태\n",
        "- 3D 텐서: 시계열 혹은 시퀀스 데이터. (samples, timesteps, features) 형태\n",
        "- 4D 텐서: 이미지. (samples, heights, width, channels) 또는 (samples, frames, heights, width)\n",
        "- 5D 텐서: 동영상. (samples, frames, heights, width, channels) 또는 (samples, frames, channels, heights, width) \n",
        "2.2.9 벡터 데이터\n",
        "- 예) 사람의 나이, 우편번호, 소득으로 구성된 데이터. feature는 3개인 벡터로 구성되며 샘플수는 10만개. (100000, 3)\n",
        "2.2.10 시계열 데이터 또는 시퀀스 데이터\n",
        "- 시간 혹은 연속된 순서가 중요한때는 시간축을 포함하여 3D 텐서로 저장. 각 샘플은 2D 텐서의 시퀀스로 인코딩되므로, 배치 데이터는 3D 텐서로 인코딩됨. 관례적으로 시간축은 두번째 축에 할당\n",
        "- 예) 시계열 - 주식 가격 데이터: 1분마다 현재 주식가격, 최고가격, 최소가격을 기록. 1분마다 데이터는 3D 벡터로 인코딩되며 하루동안의 거래는 (390분, 3)의 2D 텐서로 인코딩 됨. 250일치의 데이터는 (250, 390, 3)의 3D 텐서로 저장\n",
        "- 예) 시퀀스 - 트윗: 트윗은 128개의 알파벳으로 구성된 280개의 문자 시퀀스. 각 트윗은 (280, 128)의 2D 텐서로 인코딩 됨. 100만개의 트윗 데이터셋은 (100만, 280, 128)\n",
        "2.2.11 이미지 데이터\n",
        "- 이미지는 높이, 너비, 컬러채널(R,G,B)의 3차원으로 구성됨(흑백의 경우는 컬러채널이 없으므로 2차원). 256*256 크기의 컬러 이미지에 대한 128개의 배치는 (128, 256, 256, 3). 컬러 채널을 앞에 두는 방식(channel-first), 컬러 채널을 마지막에 두는 방식(channel-last)의 두 가지 방식이 있음\n",
        "2.2.12 비디오 데이터\n",
        "- 비디오는 프레임의 연속이며, 각 프레임은 하나의 컬러 이미지임. 여러 비디오의 배치는 (samples, frames, heights, width, channels)의 5D 텐서로 저장 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "hqVApPggTXxB",
        "outputId": "6fc55883-9ead-45bb-9e48-06aafb24ebe1"
      },
      "source": [
        "# 스칼라(0D텐서)\n",
        "import numpy as np\n",
        "x= np.array(12)\n",
        "display(x, x.ndim)\n",
        "\n",
        "# 벡터(1D텐서)\n",
        "x = np.array([12,3,6,14,7])\n",
        "display(x, x.ndim)\n",
        "\n",
        "# 행렬(2D텐서)\n",
        "x = np.array([[5,1,2,3,4],[1,2,3,4,5],[6,7,8,9,0]])\n",
        "display(x, x.ndim)\n",
        "\n",
        "# 3D, 고차원 텐서\n",
        "x = np.array([[[5,1,2,3,4]],[[1,2,3,4,5]],[[6,7,8,9,0]]])\n",
        "display(x, x.ndim)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array(12)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([12,  3,  6, 14,  7])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[5, 1, 2, 3, 4],\n",
              "       [1, 2, 3, 4, 5],\n",
              "       [6, 7, 8, 9, 0]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[5, 1, 2, 3, 4]],\n",
              "\n",
              "       [[1, 2, 3, 4, 5]],\n",
              "\n",
              "       [[6, 7, 8, 9, 0]]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq2NMeYJZaUo",
        "outputId": "2018c6bb-4d81-4c7d-9816-6914d3933d4d"
      },
      "source": [
        "# 텐서의 핵심속성\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) =  mnist.load_data()\n",
        "print(f'ranks : {train_images.ndim}')\n",
        "print(f'shape : {train_images.shape}')\n",
        "print(f'dtype : {train_images.dtype}')\n",
        "\n",
        "### 28X28의 정수 행렬(uint8)이 60000개 있는 배열\n",
        "### 각 행렬은 하나의 흑백 이미지이고, 행렬의 원소는 0~255 사이의 값을 가짐(흑백의 정도에 따른 값)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ranks : 3\n",
            "shape : (60000, 28, 28)\n",
            "dtype : uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aizcKRp_anNi",
        "outputId": "b95b4477-f461-41b1-d7c7-032aecfcd6c5"
      },
      "source": [
        "# train_image의 배열 및 이미지 출력하기\n",
        "import matplotlib.pyplot as plt\n",
        "display(train_images[4])\n",
        "plt.imshow(train_images[4], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n",
              "        148, 210, 253, 253, 113,  87, 148,  55,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 232,\n",
              "        252, 253, 189, 210, 252, 252, 253, 168,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  57, 242, 252,\n",
              "        190,  65,   5,  12, 182, 252, 253, 116,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 183,\n",
              "         14,   0,   0,  92, 252, 252, 225,  21,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 132, 253, 252, 146,  14,\n",
              "          0,   0,   0, 215, 252, 252,  79,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 126, 253, 247, 176,   9,   0,\n",
              "          0,   8,  78, 245, 253, 129,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  16, 232, 252, 176,   0,   0,   0,\n",
              "         36, 201, 252, 252, 169,  11,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  22, 252, 252,  30,  22, 119, 197,\n",
              "        241, 253, 252, 251,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  16, 231, 252, 253, 252, 252, 252,\n",
              "        226, 227, 252, 231,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  55, 235, 253, 217, 138,  42,\n",
              "         24, 192, 252, 143,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         62, 255, 253, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        106, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         45, 255, 253,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 218, 252,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  96, 252, 189,  42,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  14, 184, 252, 170,  11,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  14, 147, 252,  42,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KcWqYa9SIai"
      },
      "source": [
        "## 2.3 신경망의 톱니바퀴: 텐서 연산\n",
        "2.3.1 원소별 연산\\\n",
        "2.3.2 브로드캐스팅\\\n",
        "2.3.3 텐서 점곱\\\n",
        "2.3.4 텐서 크기 변환\\\n",
        "2.3.5 텐서 연산의 기하학적 해석\\\n",
        "2.3.6 딥러닝의 기하학적 해석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0GZBZ1a0kBC"
      },
      "source": [
        "## 2.4 신경망의 엔진: 그래디언트 기반 최적화\n",
        "2.4.1 변화율이란?\\\n",
        "2.4.2 텐서 연산의 변화율: 그래디언트\\\n",
        "2.4.3 확률적 경사 하강법\\\n",
        "미분 가능한 함수의 최솟값(0)인 지점을 모두 찾고 이 중 어떤 포인트의 함수 값이 가장 작은지 확인하는 것. 신경망에 적용하면 가장 작은 손실 함수의 값을 만드는 가중치의 조합을 해석적으로 찾는 것을 의미함.\\\n",
        "\n",
        "\n",
        "\n",
        "2.4.4 변화율 연결: 역전파 알고리즘\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKco0V5C7FYO"
      },
      "source": [
        "## 2.5 첫 번째 예제 다시 살펴보기\n",
        "## 2.6 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzgN853PCHyT"
      },
      "source": [
        "# 3장. 신경망 시작하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyeJYHDy1L5O"
      },
      "source": [
        "## 3.1 신경망의 구조\n",
        "- 층, 입력데이터와 타깃, 손실 함수, 옵티마이저\n",
        "- 연속된 층으로 구성된 네트워크가 입력 데이터를 예측으로 매핑. 손실 함수는 예측과 타깃을 비교하여 네트워크의 예측이 기댓값에 얼마나 잘 맞는지를 측정하는 손실 값을 만듦. 옵티마이저는 손실 값을 사용하여 네트워크 가중치를 업데이트함\n",
        "\n",
        "3.1.1 층: 딥러닝의 구성 단위\n",
        "- 신경망 핵심적인 데이터 구조. 층은 하나 이상의 텐서를 입력으로 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈. 어떤 종류의 층은 상태가 없지만 대부분의 경우 가중치라는 층의 상태를 가짐. 가중치는 확률적 경사 하강법에 의해 학습되는 하나 이상의 텐서이며 여기에 네트워크가 학습한 지식이 담겨 있음.\n",
        "- 층마다 적절한 텐서 포맷과 데이터 처리 방식이 다름. 예를 들어 (samples, features) 크기 의 2D 텐서가 저장된 간단한 벡터 데이터는 완전 연결 층(fully connected layer)이나 밀집 층(dense laver) 이라고도 불리는 밀집 연결 층(densely connected layer)에 의해 처리되는 경우가 많습니다(케라스에서는 Dense 클래스입니다)\n",
        "- (samples, timesteps, features) 크기의 3D 텐서로 저장된 시퀀스 데이터는 보통 LSTM 같은 순환 층(recurrent layer)에 의해 처리됨\n",
        "- 4D 텐서로 저장되 어 있는 이미지 데이터는 일반적으로 2D 합성곱 층(convolution layer)에 의해 처리됩니다(Conv2D\n",
        "클래스).\n",
        "- 플랫튼(Flatten), 풀링(Pooling), 드롭아웃(Dropout)층에는 학습되는 가중치가 없음. 보통 신경망의 가중치를 상태라고 표현하지는 않습니다. 순환 신경망의 셀(Cell) 출력은 셀의 상태라고 표현함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3.1.2 모델: 층의 네트워크\\\n",
        "\n",
        "\n",
        "3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evPj65Mq1Php"
      },
      "source": [
        "## 3.2 케라스 소개\n",
        "3.2.1 케라스, 텐서플로, 씨아노, CNTK\\\n",
        "3.2.2 케라스를 사용한 개발: 빠르게 둘러보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUufXQSi1GEl"
      },
      "source": [
        "## 3.3 딥러닝 컴퓨터 셋팅\n",
        "3.3.1 주피터 노트북: 딥러닝 실험을 위한 최적의 방법\\\n",
        "3.3.2 케라스 시작하기: 두 가지 방법\\\n",
        "3.3.3 클라우드에서 딥러닝 작업을 수행했을 때 장단점\\\n",
        "3.3.4 어떤 GPU 카드가 딥러닝에 최적일까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78iPDjkd7Mnu"
      },
      "source": [
        "## 3.4 영화 리뷰 분류: 이진 분류 예제\n",
        "3.4.1 IMDB 데이터셋\\\n",
        "3.4.2 데이터 준비\\\n",
        "3.4.3 신경망 모델 만들기\\\n",
        "3.4.4 훈련 검증\\\n",
        "3.4.5 훈련된 모델로 새로운 데이터에 대해 예측하기\\\n",
        "3.4.6 추가 실험\\\n",
        "3.4.7 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "LHn4CZ_4-Q3W",
        "outputId": "c769d0e8-7f56-400d-9dd9-ce9e7f24efc3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels)\\\n",
        " = imdb.load_data(num_words=10000)\n",
        " # num_words=10000: 훈련 데이터에서 자주 나타나는 단어 1만개만 사용"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "14573568/17464789 [========================>.....] - ETA: 0s"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-665169d48199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m  \u001b[0;31m# num_words=10000: 훈련 데이터에서 자주 나타나는 단어 1만개만 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'imdb.npz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m       '69664113be75683a8fe16e3ed0ab59fda8886cb3cd7ada244f7d9544e4676b9f')\n\u001b[0m\u001b[1;32m    108\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unexpected-keyword-arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mchunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreporthook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m           \u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mdl_progress\u001b[0;34m(count, block_size, total_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mProgressTracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mProgressTracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'URL fetch failure on {}: {} -- {}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKsD3fC5_srC"
      },
      "source": [
        "# train_data 데이터 형태 파악\n",
        "print(train_data[:5])\n",
        "print(train_data[0])\n",
        "print(len(train_data[0]))\n",
        "print(train_data.shape)\n",
        "print()\n",
        "\n",
        "import numpy as np\n",
        "print(np.sort([max(sequence) for sequence in train_data]))\n",
        "### 인덱스는 9999를 넘지 않음(자주 등장하는 단어를 1만개로 제한했기에)\n",
        "\n",
        "print(train_labels[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTcpfQCPBRjZ"
      },
      "source": [
        "# 정수 시퀀스를 이진 행렬로 인코딩\n",
        "import numpy as np \n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] =1.  # 부동소숫점 넣어줘야함\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR9p1V5wCh-j"
      },
      "source": [
        "print(x_train[0])\n",
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "633Lm0f-DB26"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdhqROPXDWKg"
      },
      "source": [
        "# 모델 정의하기\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kInm8JuSEOXu"
      },
      "source": [
        "# 모델 컴파일하기\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYhMKExEnQV"
      },
      "source": [
        "# 검증 세트 분리\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILn_YzVGFIlq"
      },
      "source": [
        "# 모델 훈련\n",
        "history = model.fit(partial_x_train, partial_y_train,\\\n",
        "                    epochs=20, batch_size=512,\\\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2mNnX-mFm0v"
      },
      "source": [
        "# 훈련과 검증 손실 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwQ5xGFtHiZ0"
      },
      "source": [
        "plt.clf()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uucaE1pLJBWJ"
      },
      "source": [
        "# 모델을 처음부터 다시 훈련하기\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "print(model.evaluate(x_test, y_test))  # 정확도 87%\n",
        "print(model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBh-lxge9X2S"
      },
      "source": [
        "## 3.5 뉴스 기사 분류: 다중 분류 문제\n",
        "3.5.1 로이터 데이터셋\\\n",
        "3.5.2 데이터 준비\\\n",
        "3.5.3 모델 구성\\\n",
        "3.5.4 훈련 검증\\\n",
        "3.5.5 새로운 데이터에 대해 예측하기\\\n",
        "3.5.6 레이블과 손실을 다루는 다른 방법\\\n",
        "3.5.7 충분히 큰 중간층을 두어야 하는 이유\\\n",
        "3.5.8 추가 실험\\\n",
        "3.5.9 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne7Dtur29awp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGDhNuYd99j6"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import pandas as pd\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)  # 매개변수는 데이터에서 가장 자주 등장하는 단어 1만개로 제한\n",
        "print(len(train_data), len(test_data))\n",
        "print(train_data[0])  # 단어 인덱스 형태\n",
        "print(pd.Series(train_labels).nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhczYg_g_XYL"
      },
      "source": [
        "# 데이터 인코딩(벡터 변환)\n",
        "import numpy as np \n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] =1.  # 부동소숫점 넣어줘야함\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBKbEYqK_7r-"
      },
      "source": [
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu9JWD9SASax"
      },
      "source": [
        "# 원핫 인코딩 방법\n",
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjIDwTx9BBLk"
      },
      "source": [
        "len(one_hot_train_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTc8lD_FBNHE"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TXx99RiCEEe"
      },
      "source": [
        "# 모델 정의하기\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CFGxcA3EGoI"
      },
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn5_JZfWERXX"
      },
      "source": [
        "# 검증 세트 준비하기\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r_dYvOPEtuX"
      },
      "source": [
        "# 모델 훈련하기\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvKbBU4iFt8D"
      },
      "source": [
        "# 훈련과 검증 손실 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYDVlXKhGZ31"
      },
      "source": [
        "# 훈련과 검증 정확도 그리기\n",
        "plt.clf()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation acc')\n",
        "plt.show()\n",
        "\n",
        "### 9번째 epoch이후에 과대적합. 아홉번의 에포크로 새로운 모델 훈련하고 테스트 세트에서 평가 필요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUi9V9UZKxPs"
      },
      "source": [
        "# 모델 처음부터 다시 훈련\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpch5IFsL3Zn"
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "print(predictions[0].shape)\n",
        "print(np.sum(predictions[0]))\n",
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArJapJJfN9jl"
      },
      "source": [
        "# 정보 병목이 있는 모델\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=128, validation_data=(x_val, y_val))\n",
        "\n",
        "### 중간층의 차원이 출력층의 차원보다 작은 경우, 많은 정보를 저차원의 표현 공간으로 압축하려 하기에 정보 손실이 발생함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI58oFGF7REA"
      },
      "source": [
        "## 3.6 주택 가격 예측: 회귀 문제\n",
        "3.6.1 보스턴 주택 가격 데이터셋\\\n",
        "3.6.2 데이터 준비\\\n",
        "3.6.3 모델 구성\\\n",
        "3.6.4 K-겹 검증을 사용한 훈련 검증\\\n",
        "3.6.5 정리\n",
        "\n",
        "## 3.7 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAmkzLbwIaSJ"
      },
      "source": [
        "3.6.1 보스턴 주택 가격 데이터셋\n",
        "- CRIM - per capita crime rate by town\n",
        "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "- INDUS - proportion of non-retail business acres per town.\n",
        "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "- NOX - nitric oxides concentration (parts per 10 million)\n",
        "- RM - average number of rooms per dwelling\n",
        "- AGE - proportion of owner-occupied units built prior to 1940\n",
        "- DIS - weighted distances to five Boston employment centres\n",
        "- RAD - index of accessibility to radial highways\n",
        "- TAX - full-value property-tax rate per $10,000\n",
        "- PTRATIO - pupil-teacher ratio by town\n",
        "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "- LSTAT - % lower status of the population\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvBakA_ElDD"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw7JwDaBG7HY"
      },
      "source": [
        "print(train_data.shape, test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta9Cp8__HQff"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB06U4w0HnEd"
      },
      "source": [
        "train_targets[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HrUHFJaIjNt"
      },
      "source": [
        "3.6.2 데이터 준비\n",
        "- 피쳐별로 스케일이 다르기에 정규화가 필요함\n",
        "- 각 관측에서 평균을 빼고 표준편차로 나누어 직접 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSL7tj28IkkF"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "train_data -= mean\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std  # test 데이터도 train 데이터에서 나온 mean, std로 표준화 해줘야함\n",
        "\n",
        "print(train_data[0])\n",
        "print(test_data[0])\n",
        "\n",
        "### test 데이터를 정규화할때 사용한 값이 훈련 데이터에서 계산한 값이어야 함\n",
        "### 머신러닝 작업과정에서 절대로 test 데이터에서 사용한 어떤 값도 사용하면 안됨\n",
        "### train, test를 다른 스케일로 변환하게 되면 train에서 학습한 정보가 쓸모없게 됨"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kskWbpKSN1"
      },
      "source": [
        "3.6.3 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlInh0w-JLBO"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  # 모델의 훈련 데이터가 적기에, 과대적합 피하기 위해 은닉층의 수가 적은 모델(1~2개)이 좋음\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  # model.compile(optimizer='rmsprop', loss='mse', metrics=[metrics.MeanAbsoluteError()])\n",
        "\n",
        "  # 회귀이기에 손실함수:mse, 평가지표:mae\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2vsn-MbLxuz"
      },
      "source": [
        "3.6.4 K-겹 검증을 사용한 훈련 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ZiVJ1ELzCv"
      },
      "source": [
        "# K-fold 검증하기\n",
        "import numpy as np\n",
        "k=4\n",
        "num_val_samples = len(train_data) // k  # k로 나눈 몫만 사용\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('처리중인 폴드 #',i)\n",
        "  val_data = train_data[i*num_val_samples: (i+1)*num_val_samples]\n",
        "  val_targets = train_targets[i*num_val_samples: (i+1)*num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [train_data[:i*num_val_samples],\n",
        "       train_data[(i+1)*num_val_samples:]],axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [train_targets[:i*num_val_samples],\n",
        "       train_targets[(i+1)*num_val_samples:]], axis=0)\n",
        "  \n",
        "  model = build_model()\n",
        "  model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxN0sHx9RlmZ"
      },
      "source": [
        "print(all_scores)\n",
        "print(np.mean(all_scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnFQmRyuSOBW"
      },
      "source": [
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9E0oKObMIXF"
      },
      "source": [
        "# 각 폴드에서 검증 점수를 로그에 저장하기\n",
        "num_epochs =  500\n",
        "all_mae_histories = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('처리중인 폴드 #',i)\n",
        "  val_data = train_data[i*num_val_samples:(i+1)*num_val_samples]\n",
        "  val_targets = train_targets[i*num_val_samples: (i+1)*num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [train_data[:i*num_val_samples],\n",
        "       train_data[(i+1)*num_val_samples:]], axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [train_targets[:i*num_val_samples],\n",
        "       train_targets[(i+1)*num_val_samples:]], axis=0)\n",
        "  \n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_targets,\n",
        "                      validation_data=(val_data, val_targets),\n",
        "                      epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  mae_history = history.history['val_mae']\n",
        "  all_mae_histories.append(mae_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cdS3w9RbfjU"
      },
      "source": [
        "# K-fold 검증 점수 평균 기록\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qer9cZB3bzBR"
      },
      "source": [
        "# 검증 점수 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history)+1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validataion MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q63EyxcIcbVf"
      },
      "source": [
        "# 처음 10개 데이터 제외한 검증 점수 그래프 그리기\n",
        "\n",
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous*factor + point*(1-factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "\n",
        "plt.plot(range(1,len(smooth_mae_history)+1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dLjqgLKdgL-"
      },
      "source": [
        "# 최종 모델 훈련하기\n",
        "\n",
        "model = build_model()\n",
        "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsjaWBAim_qT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Y5EGlAVlGu"
      },
      "source": [
        "# 4장. 머신러닝의 기본 요소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXXh3mTAVqPT"
      },
      "source": [
        "## 4.1 머신러닝의 네 가지 분류\n",
        "4.1.1 지도학습\n",
        "4.1.2 비지도학습\n",
        "4.1.3 자기 지도 학습\n",
        "- Autoencoder\n",
        "4.1.4 강화 학습\n",
        "- 알파고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6L43WxZWt4z"
      },
      "source": [
        "## 4.2 머신 러닝 모델 평가\n",
        "4.2.1 훈련, 검증, 테스트 세트\\\n",
        "4.2.2 기억해야 할 것\n",
        "- 대표성 있는 데이터\n",
        "- 시간의 방향\n",
        "- 데이터 중복 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGL5-Ze-XfZT"
      },
      "source": [
        "## 4.3 데이터 전처리, 특성 공학, 특성 학습\n",
        "4.3.1 신경망을 위한 데이터 전처리\n",
        "- 벡터화\n",
        "- 값 정규화\n",
        "- 누락된 값 다루기\n",
        "- 특성 추출\n",
        "\n",
        "4.3.2 특성 공학(Feature Engineering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpAzZFFQY8N_"
      },
      "source": [
        "## 4.4 과대적합과 과소적합\n",
        "- 과대적합 방지 방법\n",
        "  - 훈련 데이터를 더 모음\n",
        "  - 네트워크의 용량을 감소시킴\n",
        "  - 가중치 규제를 추가\n",
        "  - 드롭아웃 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD3FwF37YulF"
      },
      "source": [
        "4.4.1 네트워크 크기 축소"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ5G-QJnPhff"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)\n",
        "# 레이블을 벡터로 변환합니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46tPTqO7Qhye"
      },
      "source": [
        "# 원본 모델\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "original_model = models.Sequential()\n",
        "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "original_model.add(layers.Dense(16, activation='relu'))\n",
        "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "original_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_3XyL4QonH"
      },
      "source": [
        "# 작은 용량의 모델\n",
        "smaller_model = models.Sequential()\n",
        "smaller_model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
        "smaller_model.add(layers.Dense(6, activation='relu'))\n",
        "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "smaller_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNeCg2hlRn3d"
      },
      "source": [
        "original_hist = original_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrCvubx5SyRR"
      },
      "source": [
        "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abecKWOySbky"
      },
      "source": [
        "epochs=range(1,21)\n",
        "original_val_loss = original_hist.history['val_loss']\n",
        "smaller_val_loss = smaller_model_hist.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSF3ErYS95G"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, smaller_val_loss, 'bo', label='Small model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylAZxrU4UWd5"
      },
      "source": [
        "# 큰 용량의 모델\n",
        "bigger_model = models.Sequential()\n",
        "bigger_model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
        "bigger_model.add(layers.Dense(1024, activation='relu'))\n",
        "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "bigger_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AET282tKUoIX"
      },
      "source": [
        "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
        "                                   epochs=20, batch_size=512,\n",
        "                                   validation_data=(x_test, y_test))\n",
        "epochs=range(1,21)\n",
        "original_val_loss = original_hist.history['val_loss']\n",
        "bigger_val_loss = bigger_model_hist.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG4Hwr5QUhfL"
      },
      "source": [
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_val_loss, 'bo', label='Big model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 용량이 큰 네트워크는 첫번째 에포크 이후 바로 과대적합 시작. 검증손실도 불안정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdFfBhgTXHIO"
      },
      "source": [
        "original_train_loss = original_hist.history['loss']\n",
        "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
        "\n",
        "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, bigger_model_train_loss, 'bo', label='Bigger model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Traning loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 용량이 큰 네트워크는 훈련 손실이 매우 빠르게 0에 가까워짐\n",
        "### 용량이 많은 네트워크일수록 더 빠르게 훈련 데이터를 모델링 할 수 있음(훈련 손실이 낮아짐)\n",
        "### 그러나 과대 적합에 민감해짐(훈련과 검증 손실 사이에 큰 차이가 발생함)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niN4jj_7Y39a"
      },
      "source": [
        "4.4.2 가중치 규제 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z2CnpJpY6zB"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "l2_model = models.Sequential()\n",
        "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu', input_shape=(10000,)))\n",
        "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),\n",
        "                          activation='relu'))\n",
        "l2_model.add(layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0sSZvLzd2lz"
      },
      "source": [
        "l2_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgHQE26wd7Uc"
      },
      "source": [
        "l2_model_hist = l2_model.fit(x_train, y_train,\n",
        "                             epochs=20, batch_size=512,\n",
        "                             validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efu_70faec4v"
      },
      "source": [
        "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### 두 모델이 동일한 파라미터수를 가지고 있더라도 L2규제를 사용한 모델이 기본 모델보다 과대적합에 잘 견디고 있음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FBs93ADfu3T"
      },
      "source": [
        "### l1(0.001) 모델과 비교해보기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BefQN-Txf4qH"
      },
      "source": [
        "4.4.3 드롭아웃 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNcG0Saf70S"
      },
      "source": [
        "dpt_model = models.Sequential()\n",
        "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(16, activation='relu'))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "dpt_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ItoG-viSXQ"
      },
      "source": [
        "dpt_model_hist = dpt_model.fit(x_train, y_train, epochs=20,\n",
        "                               batch_size=512,\n",
        "                               validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnuGrhl1iokQ"
      },
      "source": [
        "dpt_model_val_loss = dpt_model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
        "plt.plot(epochs, dpt_model_val_loss, 'bo', label='Dropout-regularized model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-137JwEjrnw"
      },
      "source": [
        "## 4.5 보편적인 머신 러닝 작업 흐름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq77D4Wt3eLd"
      },
      "source": [
        "# 5장. 컴퓨터 비전을 위한 딥러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liOOnrhh3mdF"
      },
      "source": [
        "## 5.1 합성곱 신경망 소개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sEQ3hxP6fvi"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/drive/MyDrive/cakd3_colab/dl_keras/참고자료/cnn.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80UIeek08M7I"
      },
      "source": [
        "Image('/content/drive/MyDrive/cakd3_colab/dl_keras/참고자료/cnn2.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcPMl9KB-bIO"
      },
      "source": [
        "Image('/content/drive/MyDrive/cakd3_colab/dl_keras/참고자료/cnn3.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NByilutHDnmp"
      },
      "source": [
        "Image('/content/drive/MyDrive/cakd3_colab/dl_keras/참고자료/cnn5.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg_pp1vC4IHM"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSTFeLeTFuPx"
      },
      "source": [
        "model.summary()\n",
        "# 26: input 28에서 필터 3을 빼고 1을 더한 값\n",
        "\n",
        "# (28,28,1) 크기의 특성 맵을 입력으로 받아 (26,26,32) 크기의 특성 맵을 출력\n",
        "# 입력에 대해 32개의 필터를 적용하고 32개의 출력 채널 각각은 26X26 크기의 배열 값을 가진다.\n",
        "# 특성 맵의 출력 깊이는 합성곱으로 계산할 필터의 수이며 32로 시작해서 64로 끝남"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g9GXZmsGy_a"
      },
      "source": [
        "# 컨브넷 위에 분류기 추가하기\n",
        "\n",
        "# 완전연결층\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 출력층\n",
        "model.add(layers.Dense(10, activation='softmax'))  # 10가지 숫자로 분류"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lR7AT05HSQe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76M3zs2CHbOn"
      },
      "source": [
        "# MNIST 이미지에 컨브넷 훈련하기\n",
        "# feature 벡터화\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255 #0과 1사이의 값을 가지는 float값으로 변환\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUNCpyjqJbkp"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc\n",
        "\n",
        "### 2장의 완전 연결 네트워크는 97% acc가 나옴. 더 향상된 결과\n",
        "### 컨브넷이 더 간단한데 더 잘 작동하는 이유?: Conv2D, MaxPooling2D층 때문"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCDpfR_bLIrK"
      },
      "source": [
        "5.1.1 합성곱 연산\n",
        "- 완전연결층과 합성곱층 사이의 근본적 차이: 전자는 입력 특성 공간에 있는 전역패턴을 학습하나 후자는 지역패턴을 학습함. 이미지일 경우 2D 윈도우로 입력에서 패턴을 찾음\n",
        "- 컨브넷의 성질\n",
        "  - 평행 이동 불변성(translation invariant): 완전연결 네트워크는 새로운 위치에 나타난것은 새로운 패턴으로 학습해야 함. 한편 컨브넷은 이미지 특정 위치에서 패턴을 학습했을 경우 다른 곳에서도 패턴 인식이 가능함. 적은 수의 훈련 샘플을 사용하여 일반화 능력을 가진 표현을 학습 가능함. 이미지를 효율적으로 처리 가능(인간이 보는 세상도 평행 이동으로 인해 사물이 다르게 인식되지 않음)\n",
        "  - 공간적 계층 구조: 첫번째 합성곱 층이 에지 같은 작은 지역 패턴을 학습하고, 두번쨰 합성곱 층은 첫번째 층의 특성으로 구성된 더 큰 패턴을 학습하는등 계층적으로 학습하는 방식. 복잡하고 추상적인 시각적 개념을 효과적으로 학습할 수 있음(인간이 보는 세상도 공간적 계층 구조를 가짐)\n",
        "- 합성곱 연산은 특성맵(feature map)이라고 부르는 3D텐서에 적용됨. 이 텐서는 2개의 공간축(높이, 너비)과 깊이축(채널)로 구성됨. 합성곱 연산은 입력 특성맵에서 작은 패치(patch)들을 추출하고, 이런 모든 패치에 같은 변환을 적용하여 출력 특성맵(output feature map)을 만듦\n",
        "- 출력 특성맵도 3D 텐서임. 깊이는 층의 매개변수로 결정되기에 상황에 따라 다름. 깊이축(채널)은 RGB 컬러 처럼 특정 컬러를 의미하지 않으며, 일종의 필터를 의미함. 필터는 입력 데이터의 어떤 특성을 인코딩 함(예: 입력값에 얼굴이 있는지)\n",
        "- MNIST 예제에서 첫번째 합성곱 층이 (28,28,1) 크기의 특성맵을 입력으로 받아 (26,26,32) 크기의 특성맵을 출력함. 즉 입력에 대해 32개의 필터를 적용\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MwRbaZm3rBS"
      },
      "source": [
        "## 5.2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기\n",
        "- https://github.com/gilbutITbook/006975/blob/master/5.2-using-convnets-with-small-datasets.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9okBIZpFiAi"
      },
      "source": [
        "5.2.1 작은 데이터셋 문제에서 딥러닝의 타당성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07RsU57MFqd9"
      },
      "source": [
        "5.2.2 데이터 내려받기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqL_vPpAkE0"
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9QSsGy0Apbk"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Hsdy-YA-Bx"
      },
      "source": [
        "import os, shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubklRgw1BHcU"
      },
      "source": [
        "# 원본 데이터셋을 압축 해제한 디렉터리 경로\n",
        "original_dataset_dir = '/content/drive/MyDrive/cakd3_colab/dl_keras/datasets/cats_and_dogs/train'\n",
        "\n",
        "# 소규모 데이터셋을 저장할 디렉터리\n",
        "base_dir = '/content/drive/MyDrive/cakd3_colab/dl_keras/datasets/cats_and_dogs_small'\n",
        "if os.path.exists(base_dir):  # 반복적인 실행을 위해 디렉토리를 삭제합니다.\n",
        "    shutil.rmtree(base_dir)   # 이 코드는 책에 포함되어 있지 않습니다.\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# 훈련용 고양이 사진 디렉터리\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "# 훈련용 강아지 사진 디렉터리\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "# 검증용 고양이 사진 디렉터리\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "# 검증용 강아지 사진 디렉터리\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "# 테스트용 고양이 사진 디렉터리\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "# 테스트용 강아지 사진 디렉터리\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "# 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTU-IA3HFPuj"
      },
      "source": [
        "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
        "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
        "print('검증용 고양이 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))\n",
        "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))\n",
        "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
        "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQG-q7QhG0pp"
      },
      "source": [
        "5.2.3 네트워크 구성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuFu1zr5IHzV"
      },
      "source": [
        "# 강아지 vs 고양이 분류를 위한 소규모 컨브넷 만들기\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF_W_7uoH9dI"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbgLJXObLrpJ"
      },
      "source": [
        "# 모델의 훈련 설정하기\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MQJ_I7xMHS3"
      },
      "source": [
        "5.2.4 데이터 전처리\n",
        "- 데이터는 네트워크에 주입되기 전 부동 소수 타입의 텐서로 전처리 되어 있어야 함\n",
        "1. 사진 파일을 읽음\n",
        "2. jpeg 콘텐츠를 rgb픽셀 값으로 디코딩\n",
        "3. 부동 소수 타입의 텐서로 변환\n",
        "4. 픽셀값(0~255)의 스케일을 [0,1]로 조정(신경망은 작은 입력값을 선호함)\n",
        "- 케라스는 이 단계를 자동으로 처리하는 유틸리티가 있음(keras.preprocessing.image). 케라스의 ImageDataGenerator 클래스는 디스크에 있는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꾸어주는 파이썬 제너레이터를 만들어 줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVB1s_EyMLYI"
      },
      "source": [
        "#  ImageDataGenerator를 사용하여 디렉터리에서 이미지 읽기\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150,150), batch_size=20, class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBkHQfQCN5bo"
      },
      "source": [
        "# 배치 제너레이터를 사용하여 모델 훈련하기\n",
        "history = model.fit_generator # fit_generator: fit과 동일하나 데이터 제너레이터 사용 가능\n",
        "(train_generator, steps_per_epoch=100, epochs=30,  # steps_per_epoch: 횟수만큼 경사 하강법 단계를 실행\n",
        "                              validation_data=validation_generator, validation_steps=50) # validation_steps: 검증 데이터 중 제너레이터에서 얼마나 많은 배치를 추출하여 평가할지"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kCD9tAOS0R"
      },
      "source": [
        "# 모델 저장하기\n",
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDF_AmkPfEV"
      },
      "source": [
        "# 훈련의 정확도와 손실 그래프 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qArVVShORAeS"
      },
      "source": [
        "5.2.5 데이터 증식 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzwvI9SLRDbV"
      },
      "source": [
        "# ImageDataGenerator를 사용하여 데이터 증식 설정하기\n",
        "datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1,\n",
        "                             shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK9GOOFISsaU"
      },
      "source": [
        "# 랜덤하게 증식된 훈련 이미지 그리기\n",
        "\n",
        "from keras.preprocessing import image\n",
        "fnames = sorted([os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)])\n",
        "img_path = fnames[3]\n",
        "img = image.load_img(img_path, target_size=(150,150))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "  plt.figure(i)\n",
        "  imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "  i += 1\n",
        "  if i % 4 == 0:\n",
        "    break\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6BV_b1FdPRB"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPJ6IU2-dYTF"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 만들어야 합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqCfFLSfdfP2"
      },
      "source": [
        "model.save('cats_and_dogs_small_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBAB7go6dkIG"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZqRJLaY3zsC"
      },
      "source": [
        "## 5.3 사전 훈련된 컨브넷 사용하기\n",
        "- pretrained network: 대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크. 원본 데이터셋이 충분히 크고 일반적이라면 사전 훈련된 네트워크에 의해 학습된 특성의 계층 구조는 실제 세상에 대한 일반적인 모델로 효율적 역할 할 수 있음.\n",
        "- 새로운 문제가 원래 작업과 완전히 다른 클래스에 대한 것이라도 이런 특성은 많은 컴퓨터 비전 문제에 유용함.(예: 동물이나 생활용품으로 이루어진 ImageNet 데이터셋에 네트워크 훈련후, 이 네트워크를 이미지에서 가구 아이템을 식별하는 것 같은 다른 용도로 사용할 수 있음)\n",
        "- VGG16: 2014년 개발. ImageNet 데이터셋에 널리 사용되는 컨브넷 구조. 조금 오래되어 최고 성능은 못미치며 타 모델보다 무거우나, 모델 구조가 이전에 보았던것과 비슷함\n",
        "  - VGG 16, ResNet, Inception, Inception-ResNet, Xception 등으로도 불림\n",
        "  - 합성곱층 13개, 완전연결층 3개(총 16개). VGG19는 합성곱층 16개, 완전연결층 3개(총 19개)\n",
        "  - pretrained network를 사용하는 방법: Feature Extraction(특성추출), Fine Tuning(미세조정)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1YwJg0ADvE"
      },
      "source": [
        "\n",
        "5.3.1 특성 추출\n",
        "\n",
        "1. 데이터 증식을 사용하지 않는 빠른 특성 추출\n",
        "  - 새로운 데이터셋에서 합성곱 기반 층을 실행하고, 출력을 넘파이 배열로 디스크에 저장. 데이터를 독립된 완전 연결 분류기에 입력으로 사용함.\n",
        "  - 합성곱 연산은 전체 과정 중 가장 비싼 부분임. 모든 입력 이미지에 대해 합성곱 기반층을 한번만 실행하면 되기에 빠르고 비용이 적게 듦. 이 이유로 이 기법에는 데이터 증식을 사용할 수 없음\n",
        "\n",
        "2. 준비한 모델(conv_base)위에 Dense층을 쌓아 확장\n",
        "  - 그 다음 입력 데이터에서 엔드-투-엔드로 전체 모델을 실행함.\n",
        "  - 모델에 노출된 모든 입력 이미지가 매번 합성곱 기반층을 통과하기 때문에, 데이터 증식 사용 가능함. 첫번째 방식보다 비용이 많이 듦"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyeUl9sM-MpR"
      },
      "source": [
        "# VGG16 합성곱 기반 층 만들기\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
        "\n",
        "# 1. weight: 모델을 초기화할 가중치 체크포인트 지정\n",
        "# 2. include_top: 네트워크의 최상위 완전 연결 분류기 포함 여부. 기본값은 True이며, ImageNet의 클래스 1000개에 대응되는 완전 연결 분류기를 포함함.\n",
        "### 강아지와 고양이를 2개의 클래스로 구분하는 완전 연결층을 추가하려 하므로 최상위 완전 연결 분류기 포함 안함(False)\n",
        "# 3. input_shape: 네트워크에 주입할 이미지 텐서의 크기. 옵션이며 지정 안할지 어떤 크기의 입력도 처리 가능함\n",
        "### include_top=True일시 합성곱 층 위에 완전 연결층이 포함되므로 input_shape는 원본 모델과 동일한 (224,224,3)이 되어야 함"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SofxaGgkBuWb",
        "outputId": "92184354-273f-47a9-e829-d5f605bdee09"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot-ATB31B-gP",
        "outputId": "417e1e2f-2880-4c4d-ca57-a72336827d59"
      },
      "source": [
        "# 1. 데이터 증식을 사용하지 않는 빠른 특성 추출\n",
        "# 사전 훈련된 합성곱 기반 층(conv_base)을 사용한 특성 추출하기\n",
        "\n",
        "import os \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/cakd3_colab/dl_keras/datasets/cats_and_dogs_small'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size=20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "  features = np.zeros(shape=(sample_count, 4,4,512))\n",
        "  labels = np.zeros(shape=(sample_count))\n",
        "  generator = datagen.flow_from_directory(directory, target_size=(150,150), batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "  i =0\n",
        "  for inputs_batch, labels_batch in generator:\n",
        "    features_batch = conv_base.predict(inputs_batch)\n",
        "    features[i*batch_size: (i+1)*batch_size] = features_batch\n",
        "    labels[i*batch_size: (i+1)*batch_size] = labels_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= sample_count:\n",
        "      break                             # 제너레이터는 루프 안에서 무한하게 데이터를 만들어내므로, 모든 이미지를 한번씩 처리하고 나면 중지시켜야함\n",
        "  return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMJbR7ZNISof"
      },
      "source": [
        "# 추출된 특성의 크기는 (samples, 4,4,512)임. 완전 연결 분류기에 주입하기 위해 2D 사이즈 (samples, 8192)로 펼치기\n",
        "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
        "validation_features = np.reshape(validation_features, (1000*4*4*512))\n",
        "test_features = np.reshape(test_features, (1000*4*4*512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw6L9TccI6sJ"
      },
      "source": [
        "# 완전 연결 분류기를 정의하고 훈련하기\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers \n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(train_features, train_labels, epochs=30, batch_size=20, validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DttlzY6L12-"
      },
      "source": [
        "# 결과 그래프 그리기\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4e5REPO32z8"
      },
      "source": [
        "## 5.4 컨브넷 학습 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0sSA4CW35ry"
      },
      "source": [
        "## 5.5 요약"
      ]
    }
  ]
}